---
title: 'Paper reading 8'
date: 2025-03-22
permalink: /posts/2025/03/blog-post-3/
tags:
  - cool posts
  - category1
  - category2
---

# 论文阅读

### HYMBA: A HYBRID-HEAD ARCHITECTURE FOR SMALL LANGUAGE MODELS

- motivation: Mamba通过引入状态空间模型(SSM)将复杂度优化为了线性的，又优化了硬件占用情况，解决了transformer推理时间的KV cache问题。由于低分辨率记忆，SSM在回忆和推理准确性方面有待提高。

- novelty: 提出一种att头和ssm头的融合机制，二者对相同的输入并行处理，然后进行互补，允许每一层同时利用高分辨率的注意力回忆和有效的ssm上下文摘要，增加模型在处理各种类型的信息流和记忆访问模式方面的灵活性和表现力。

  ![img1](../../../../images/20250322/image.png)

  ![img2](../../../../images/20250322/image-1.png)

  ![img3](../../../../images/20250322/image-2.png)

  ![img4](../../../../images/20250322/image-3.png)

  beta1和beta2是可学习的向量，分别重新缩放来自注意力和SSM头部的输出的每个通道。


### It Helps to Take a Second Opinion: TEACHING SMALLER LLMS TO DELIBERATE MUTUALLY VIA SELECTIVE RATIONALE OPTIMISATION

- motivation: 通过LLM的反馈去增强SLM这一方法没有实际的应用价值？如果说能够不依赖于LLM去提升SLM的性能就好了。LLM强在哪：1.能够循序渐进地“思考”；2.能够自我优化（从DS-R1可以明显地感觉到），因此本文着眼于不依赖LLM的反馈使SLM能够拥有逻辑思考的能力和自我优化的能力。

- novelty:由于规模和探索能力的限制，小模型会陷入冗余的推理路径中。用CoT数据集对小模型进行微调，使其具备逐步思考的能力？再用微调后的SLM生成rationals，再进行微调，使其具备自我优化的能力。本人认为这两点不足以构成创新，本文比较有参考价值的地方在于对两个SLM生成结果的选择机制，即如何根据评分去选择，奈何篇幅太少。

  ![img5](../../../../images/20250322/image-4.png)

  ![img6](../../../../images/20250322/image-5.png)

- inspiration:要么选择，要么融合